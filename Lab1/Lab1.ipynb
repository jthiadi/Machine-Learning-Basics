{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee_4o27S-PhO",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Introduction**\n",
    "\n",
    "- The used car market is large and dynamic, with prices influenced by multiple factors such as mileage, engine size, fuel efficiency, year of manufacture, and brand. For buyers, accurate price predictions help them avoid overpaying, while for sellers and dealerships, predictive models can guide competitive pricing strategies.\n",
    "\n",
    "- In this lab, students will need to develop predictive models to accurately estimate the used car price based on the car information.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Used car](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTwsNyFobkAjOIx4t1z4eublgdP90ALrglnIA&s)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BOyiK5o-PhP"
   },
   "source": [
    "# **Environment**\n",
    "\n",
    "- We will be using .ipynb (Jupyter Notebook) files. If you don’t already have an environment to run these files, we recommend using **Anaconda**.\n",
    "\n",
    "- The **coding exam** will also use Anaconda, so it’s a good idea to get familiar with it. For guidance, refer to the tutorial anaconda_guide.pptx.\n",
    "\n",
    "- If you are unsure about a function or its parameters, you can use help() to view its documentation. For example: help(train_test_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7zC0h8w-PhP"
   },
   "source": [
    "# **Requirement**\n",
    "\n",
    "- Do it individually! Not as a team! (The team is for final project)\n",
    "\n",
    "- Deadline: **2025/9/25 23:59** (Late submission is not allowed!)\n",
    "\n",
    "- Hand in following files to eeclass in the following format (Do not compressed!)\n",
    "\t- Lab1.ipynb\n",
    "\t- Lab1_basic.csv\n",
    "\t- Lab1_advanced.csv\n",
    "\n",
    "- Lab 1 would be covered on the coding and writing exam next time.\n",
    "\n",
    "- You may modify the provided sample code or add new cells as needed, as long as you meet the requirements.\n",
    "\n",
    "- Responsible TA: Pin-Shun Wang (wangpinshun@gmail.com)\n",
    "\t- Email for questions or visit EECS 639 during TA hours (Make a reservation in advance).\n",
    "\t- No debugging service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33QrHTbA-PhP"
   },
   "source": [
    "# **Penalty Rules**\n",
    "\n",
    "0 points if any of the following conditions happened\n",
    "- Plagiarism\n",
    "- Late submission\n",
    "- Not using the template or importing any other packages\n",
    "- No code(“Lab1.ipynb”) submission on eeclass\n",
    "- No prediction csv files submission on eeclass\n",
    "- Your submission was not generated by your code\n",
    "\n",
    "5 Points would be deducted if your submission format is incorrect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMASY5gD9L0K"
   },
   "source": [
    "# **Lab1: Regression**\n",
    "In this lab, you are required to complete the following tasks:\n",
    "\n",
    "1.  Part I (**60%**) - Preprocess data and implement a linear regression model to predict used car price\n",
    "\n",
    "    - Step 1: Split Data\n",
    "    - Step 2: Preprocess Data\n",
    "    - Step 3: Train Model and Generate Result\n",
    "\n",
    "2.  Part II  (**35%**) - Extend the linear regression model in part I to polynomial regression model and improve prediction performance\n",
    "\n",
    "    - Step 1: Generate the Polynomial Features\n",
    "    - Step 2: Train Model and Generate Result\n",
    "\n",
    "3. Part III (**5%**) – Write a report that answers the given questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egBMMLGV_X_x"
   },
   "source": [
    "### Import Packages\n",
    "\n",
    "⚠️You **cannot** import any other package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WhhUTua487C-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iuXHvhLALwz"
   },
   "source": [
    "### Global attributes\n",
    "- Define the global attributes. You can also add your own global attributes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wXZVhdp8-flF"
   },
   "outputs": [],
   "source": [
    "training_dataroot = 'train.csv' # Training data file file named as 'train.csv'\n",
    "testing_dataroot = 'test.csv'   # Testing data file named as 'test.csv'\n",
    "basic_output_path = 'Lab1_basic.csv' # Your model prediction in part I to submit to eeclass\n",
    "advanced_output_path = 'Lab1_advanced.csv' # Your model prediction in part II to submit to eeclass\n",
    "\n",
    "basic_output =  [] # save your model prediction in part I\n",
    "advanced_output = [] # save your model prediction in part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyTqIRxQAtWj"
   },
   "source": [
    "### Load the Input File\n",
    "\n",
    "First, load the input file **train.csv** and **test.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KUzYjoq9AwRp",
    "outputId": "e4faed1e-4af3-433e-fe74-a3bb4be8bd8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B Class</td>\n",
       "      <td>2017</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>26704</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>68.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CL Class</td>\n",
       "      <td>2020</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>55.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V Class</td>\n",
       "      <td>2018</td>\n",
       "      <td>Manual</td>\n",
       "      <td>24164</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>46.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>19498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2017</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>28078</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>65.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C Class</td>\n",
       "      <td>2019</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>15838</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>61.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  year transmission  mileage fuelType  tax   mpg  engineSize  \\\n",
       "0    B Class  2017    Semi-Auto    26704   Diesel  145  68.9         2.1   \n",
       "1   CL Class  2020    Semi-Auto     1000   Diesel  145  55.4         2.0   \n",
       "2    V Class  2018       Manual    24164   Diesel  145  46.3         2.1   \n",
       "3    E Class  2017    Semi-Auto    28078   Diesel  145  65.7         2.0   \n",
       "4    C Class  2019    Semi-Auto    15838   Diesel  145  61.4         2.0   \n",
       "\n",
       "   price  \n",
       "0  13999  \n",
       "1  30389  \n",
       "2  19498  \n",
       "3  21799  \n",
       "4  24498  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Class</td>\n",
       "      <td>2019</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>8478</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>65.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2014</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>60514</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>52.3</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2020</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>2568</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>42.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLC Class</td>\n",
       "      <td>2020</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>2000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C Class</td>\n",
       "      <td>2017</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>20949</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>61.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  year transmission  mileage fuelType  tax   mpg  engineSize\n",
       "0     A Class  2019    Automatic     8478   Diesel  145  65.7         1.5\n",
       "1     E Class  2014    Automatic    60514   Diesel  145  52.3         2.1\n",
       "2     E Class  2020    Automatic     2568   Diesel  145  42.8         2.0\n",
       "3   GLC Class  2020    Semi-Auto     2000   Diesel  145  40.9         2.0\n",
       "4     C Class  2017    Automatic    20949   Diesel  145  61.4         2.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data:  10495\n",
      "Number of testing data:  2624\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(training_dataroot)\n",
    "df_test = pd.read_csv(testing_dataroot)\n",
    "\n",
    "display(df_train.head(5))\n",
    "display(df_test.head(5))\n",
    "print(\"Number of training data: \", len(df_train))\n",
    "print(\"Number of testing data: \", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNpd_FfX_BXI"
   },
   "source": [
    "---\n",
    "# 1. Part I (60%)\n",
    "In part I, you need to implement the linear regression to predict used car price.\n",
    "\n",
    "You will receive full credit (60 points) if the MAPE of your predictions on the testing data is below **20**.\n",
    "\n",
    "⚠️**Please save the prediction result for the testing data in a CSV file and submit it to eeclass. This file will be used to evaluate your assignment**⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bqYH_MvBv4v"
   },
   "source": [
    "## Step 1: Split data\n",
    "\n",
    "Use **train_test_split** from scikit-learn to divide the dataset into a training set and a validation set. The training set is used to fit your regression model, while the validation set is used to evaluate its performance.\n",
    "\n",
    "- **We recommend setting random_state=0 in train_test_split to ensure that the validation data is representative and the evaluation is consistent with the testing data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NVV1mrnM-PhS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>GLC Class</td>\n",
       "      <td>2020</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2019</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>8000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>45.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2019</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>11210</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>150</td>\n",
       "      <td>72.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>C Class</td>\n",
       "      <td>2019</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>13027</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>61.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>E Class</td>\n",
       "      <td>2016</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>29511</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>30</td>\n",
       "      <td>65.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  year transmission  mileage fuelType  tax   mpg  engineSize\n",
       "6880   GLC Class  2020    Semi-Auto     4000   Diesel  145  40.9         2.0\n",
       "4629     E Class  2019    Automatic     8000   Diesel  145  45.6         2.0\n",
       "1536     E Class  2019    Automatic    11210   Diesel  150  72.4         2.0\n",
       "5570     C Class  2019    Semi-Auto    13027   Diesel  145  61.4         2.0\n",
       "6593     E Class  2016    Semi-Auto    29511   Diesel   30  65.7         2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6880    46481\n",
       "4629    31995\n",
       "1536    24250\n",
       "5570    25899\n",
       "6593    19998\n",
       "Name: price, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Split df_train into training set and validation set\n",
    "\n",
    "X = df_train.drop(columns=['price'])  # features (smua kecuali price)\n",
    "y = df_train['price']                 # price = target variable\n",
    "\n",
    "# Split data into training and validation sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split( # X n Y sama\" dipisah buat train and validation, validation 18.5% sisanya train\n",
    "    X, y, test_size=0.185, random_state=0\n",
    ") # set parameter random_state=0\n",
    "\n",
    "display(x_train.head(5))\n",
    "display(y_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-miSLyewCeME"
   },
   "source": [
    "## Step 2: Preprocess Data\n",
    "\n",
    "As we can see from the input file, the scales of the input features vary significantly. Therefore, it is important to standardize them first to ensure that no single feature dominates the regression results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twrzyvm5-PhS"
   },
   "source": [
    "### Step 2-1: Standardize Continuous Value\n",
    "\n",
    "- As we can see from the input file, the scales of the input features vary significantly. Therefore, it is important to standardize them first to ensure that no single feature dominates the regression results.\n",
    "\n",
    "- Try to use StandardScaler() to transform both the training and validation data.\n",
    "\n",
    "**Note**: Always fit the scaler on the training data only (to compute the mean and standard deviation), and then use the same scaler to transform both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jR4TYnwwCrci"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before standardization: [2.02e+03 4.00e+03 1.45e+02 4.09e+01 2.00e+00] [2.013e+03 3.100e+04 1.450e+02 5.540e+01 2.200e+00]\n",
      "After standardization: [ 1.21110625 -0.85200702  0.24519601 -0.94338844 -0.11776907] [-1.92351861  0.42389884  0.24519601  0.00404356  0.23516676]\n"
     ]
    }
   ],
   "source": [
    "cont_columns = ['year', 'mileage', 'tax','mpg', 'engineSize']\n",
    "example_train = x_train[cont_columns]\n",
    "example_valid = x_valid[cont_columns]\n",
    "print(\"Before standardization:\", example_train.iloc[0].values, example_valid.iloc[0].values)\n",
    "\n",
    "# TODO Standardize both example_train and example_valid.\n",
    "scaler = StandardScaler()\n",
    "scale_train = scaler.fit_transform(example_train)  # fit on training set biar ga liat validation pny\n",
    "scale_valid = scaler.transform(example_valid)      \n",
    "print(\"After standardization:\", scale_train[0], scale_valid[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwqNbxP5-PhS"
   },
   "source": [
    "### Step 2-2: Encode Categorical Value\n",
    "\n",
    "- The dataset contains several categorical columns. For example, the model column has 26 distinct car models. Since regression models cannot directly handle categorical values, we need to encode these features first.\n",
    "\n",
    "- We can use one hot encoding to tackle such issue. It can creates a new binary feature for each distinct category. The column corresponding to the observed category is set to 1, while all others are 0.\n",
    "\n",
    "**Note**: Just like with scaling, you should fit the encoder on the training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZIg-_uRN-PhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encoding:\n",
      "Feature: ['model' 'transmission' 'fuelType']\n",
      "====================================================================================================\n",
      "After encoding:\n",
      "Feature: ['model_ A Class' 'model_ B Class' 'model_ C Class' 'model_ CL Class'\n",
      " 'model_ CLA Class' 'model_ CLC Class' 'model_ CLK' 'model_ CLS Class'\n",
      " 'model_ E Class' 'model_ G Class' 'model_ GL Class' 'model_ GLA Class'\n",
      " 'model_ GLB Class' 'model_ GLC Class' 'model_ GLE Class'\n",
      " 'model_ GLS Class' 'model_ M Class' 'model_ R Class' 'model_ S Class'\n",
      " 'model_ SL CLASS' 'model_ SLK' 'model_ V Class' 'model_ X-CLASS'\n",
      " 'model_180' 'model_200' 'model_220' 'model_230' 'transmission_Automatic'\n",
      " 'transmission_Manual' 'transmission_Other' 'transmission_Semi-Auto'\n",
      " 'fuelType_Diesel' 'fuelType_Hybrid' 'fuelType_Other' 'fuelType_Petrol']\n"
     ]
    }
   ],
   "source": [
    "category_columns = ['model','transmission', 'fuelType']\n",
    "example_train = x_train[category_columns]\n",
    "example_valid = x_valid[category_columns]\n",
    "\n",
    "# set handle_unknown='ignore' to prevent unseen categories in validation data\n",
    "onehotencoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# TODO Encode example_train and example_valid\n",
    "onehot_train = onehotencoder.fit_transform(example_train)   \n",
    "onehot_valid = onehotencoder.transform(example_valid)      \n",
    "\n",
    "print(\"Before encoding:\")\n",
    "print(f\"Feature: {example_train.columns.values}\")\n",
    "print('=' * 100)\n",
    "print(\"After encoding:\")\n",
    "print(f\"Feature: {onehotencoder.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGCk9pr1-PhS"
   },
   "source": [
    "### Step 2-3: Use ColumnTransformer\n",
    "\n",
    "- The input CSV file contains both continuous and categorical features. Since these types of data require different preprocessing steps, it is convenient to use ColumnTransformer in scikit-learn to apply the appropriate transformations to each column.\n",
    "\n",
    "- Using the preprocessing steps we defined earlier (scaling for continuous features and one-hot encoding for categorical features), define a preprocessor that transforms the input data into a format suitable for linear regression, all in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OFkak7q9-PhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8553, 40)\n",
      "(1942, 40)\n"
     ]
    }
   ],
   "source": [
    "# TODO Define the preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"numerical\", scaler, cont_columns),\n",
    "    (\"category\", onehotencoder, category_columns)\n",
    "])\n",
    "\n",
    "# TODO Preprocess continuous data and categorical data at the same time\n",
    "preprocess_train = preprocessor.fit_transform(x_train)  \n",
    "preprocess_valid = preprocessor.transform(x_valid)      \n",
    "\n",
    "print(preprocess_train.shape)\n",
    "print(preprocess_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q4qKXbDDmG9"
   },
   "source": [
    "## Step 3: Train Model and Generate Result\n",
    "\n",
    "- Now that you know how to preprocess the data, let’s train a linear regression model. For convenience, you don’t need to preprocess the data separately before training. Instead, you can use a **Pipeline** to combine the preprocessor and the regression model, so that you can perform preprocessing and model training in a single step.\n",
    "\n",
    "- In this lab, we use Mean Absolute Percentage Error (MAPE) to evaluate the performance. It measures the average absolute difference between the predicted and actual values, expressed as a percentage of the actual values. It is more interpretable because it provides a relative error in percentage terms, making it easier to understand and compare across different datasets or scales. You can calculate it with the imported function **mean_absolute_percentage_error**. The formula is as below:\n",
    "<div align=\"center\">\n",
    "\n",
    "![MAPE_formula](https://ithelp.ithome.com.tw/upload/images/20210929/20142004n36Qnhw9js.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "- Save the predicted values for the testing dataset in `basic_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coo82WvZDpMq"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# TODO Fit the model\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# TODO Evaluate your model using validation data\n",
    "y_pred = pipeline.predict(x_valid)\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_valid, y_pred)\n",
    "print(\"MAPE (%):\", mape * 100)\n",
    "\n",
    "# TODO Predict used car price in the testing data\n",
    "basic_output = pipeline.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = pipeline.named_steps[\"model\"]\n",
    "\n",
    "#feature_names = pipeline.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "#feature = [name.split(\"__\")[-1] for name in feature_names]\n",
    "\n",
    "#coefficients = model.coef_#\n",
    "#intercept = model.intercept_\n",
    "\n",
    "#equation_terms = []\n",
    "#for coef, name in zip(coefficients, feature):\n",
    "#    if abs(coef) > 1e-8:  # skip ~zero terms\n",
    "#        equation_terms.append(f\"({coef:.4f} * {name})\")\n",
    "\n",
    "#equation = \" + \".join(equation_terms)\n",
    "#equation = f\"price = {intercept:.4f} + \" + equation\n",
    "#print(equation)\n",
    "\n",
    "#coef_str = \", \".join([f\"{coef:.4f}\" for coef in coefficients])\n",
    "\n",
    "#print(coef_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW3NrFmGEEiG"
   },
   "source": [
    "### Write the Output File\n",
    "\n",
    "Write the prediction in *basic_output* to Lab1_basic.csv\n",
    "> Format: 'ID', 'price'\n",
    "\n",
    "⚠️**Remember to submit it to eeclass. This file will be used to evaluate your part I**⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Mo7rdhx0EFLn"
   },
   "outputs": [],
   "source": [
    "# Assume that basic_output is a list with length = 2624\n",
    "with open(basic_output_path, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerow(['ID', 'price'])\n",
    "  for i in range(len(basic_output)):\n",
    "    writer.writerow([i,basic_output[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1O2l8d2E3he"
   },
   "source": [
    "# 2. Part II (35%)\n",
    "In part II, you need to implement the polynomial regression to improve your price predictions. Polynomial regression is useful because it can capture the non-linear relationships between the input features and the target variable.\n",
    "\n",
    "You will receive full credit (35 points) if the MAPE of your predictions on the testing data is below **15**.\n",
    "\n",
    "⚠️**Please save the prediction result for the testing data in a CSV file and submit it to eeclass. This file will be used to evaluate your assignment**⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYTyQ4Qt-PhT"
   },
   "source": [
    "---\n",
    "## Step 1: Generate the Polynomial Features\n",
    "\n",
    "To implement polynomial regression, we first need to expand the original input features into polynomial features.For example, suppose we have two input features (${x1}$, ${x2}$), and we want to generate polynomial features up to degree 3. The transformed features would include:\n",
    "- Degree 1:  (${x1}$, ${x2}$)\n",
    "- Degree 2: (${x1^2}$, ${x2^2}$, ${x1x2}$)\n",
    "- Degree 3: (${x1^3}$, ${x2^3}$, ${x1^2x2}$, ${x1x2^2}$)\n",
    "\n",
    "In total, this gives us 9 polynomial features. By applying our regression model in basic part to these expanded features, we can capture non-linear relationships between the input variables and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "UKqbxIXb-PhT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Feature shape:  (8553, 2)\n",
      "Polynomial Feature shape:  (8553, 9)\n"
     ]
    }
   ],
   "source": [
    "example_columns = ['tax', 'mpg']\n",
    "example_train = x_train[example_columns]\n",
    "example_valid = x_valid[example_columns]\n",
    "\n",
    "# set include_bias=False since the regression model would consider intercept term itself\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "# TODO Generate the polynomial features for example_train and example_valid\n",
    "poly_train = poly.fit_transform(example_train)\n",
    "poly_valid = poly.transform(example_valid)\n",
    "\n",
    "print(\"Original Feature shape: \", example_train.shape)\n",
    "print(\"Polynomial Feature shape: \", poly_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLYo34fC-PhT"
   },
   "source": [
    "## Step 2: Train Model and Generate Result\n",
    "\n",
    "Extend the **ColumnTransformer** you defined in the basic part by adding **PolynomialFeatures**, and use it to generate predictions on the testing dataset. To apply polynomial expansion and standardization together, wrap them in a Pipeline so they are processed in the correct order.\n",
    "\n",
    "**Hint**: You can experiment with different polynomial degrees, or try alternative linear models such as **Ridge** or **Lasso** regression to improve performance.\n",
    "\n",
    "- Save the predicted values for the testing dataset in `advanced_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ruw5auxI-PhT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE (%): 11.613134367256439\n"
     ]
    }
   ],
   "source": [
    "# TODO Define a new preprocessor that includes PolynomialFeatures\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"numerical\", Pipeline([\n",
    "        (\"poly\", poly),  \n",
    "        (\"scaler\", scaler)\n",
    "    ]), cont_columns),\n",
    "    (\"category\", onehotencoder, category_columns)\n",
    "])\n",
    "\n",
    "# TODO Build your own pipeline with different regression model\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", Ridge(alpha=20))  \n",
    "])\n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#params = {\"model__alpha\": [0.1, 0.5, 1, 3, 5, 10, 20, 30, 35, 100]}\n",
    "#search = GridSearchCV(pipeline, params, cv=5, scoring=\"neg_mean_absolute_percentage_error\")\n",
    "#search.fit(x_train, y_train)\n",
    "\n",
    "#print(\"Best alpha from CV:\", search.best_params_)\n",
    "\n",
    "# TODO Fit the model\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# TODO Evaluate your model using validation data\n",
    "y_pred = pipeline.predict(x_valid)\n",
    "mape = mean_absolute_percentage_error(y_valid, y_pred)\n",
    "print(\"MAPE (%):\", mape * 100)\n",
    "\n",
    "\n",
    "# TODO Predict used car price in the testing data\n",
    "advanced_output = pipeline.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRmHTp67-PhT"
   },
   "source": [
    "### Write the Output File\n",
    "\n",
    "Write the prediction in *advanced_output* to Lab1_advanced.csv\n",
    "> Format: 'ID', 'price'\n",
    "\n",
    "⚠️**Remember to submit it to eeclass. This file will be used to evaluate your part II**⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "c3alLSgU-PhT"
   },
   "outputs": [],
   "source": [
    "# Assume that advanced_output is a list with length = 2624\n",
    "with open(advanced_output_path, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerow(['ID', 'price'])\n",
    "  for i in range(len(advanced_output)):\n",
    "    writer.writerow([i,advanced_output[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_d-vJGU-PhT"
   },
   "source": [
    "# Part III (5%)\n",
    "\n",
    "Answer each question in the below markdown cell.\n",
    "\n",
    "1. Write down your regression equation in basic part. For example: 1 + 20*x1 + 30*x2 (1%)\n",
    "\n",
    "2. When standardizing input features, why do we standardize each feature across all samples, rather than standardizing each sample individually? (1%)\n",
    "\n",
    "3. Why don’t we simply map each categorical value to an integer (0 to number of classes – 1)? What advantages does one-hot encoding provide compared to this approach? (1%)\n",
    "\n",
    "4. In the advanced part, should we generate polynomial features first or standardize the data first? Explain your reasoning. (2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUCU_BiA-PhU",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Your answer to the questions\n",
    "1. 36340.2482 + (4183.3429 * year) + (-3131.3262 * mileage) + (-1291.2512 * tax) + (-2573.7598 * mpg) + (5215.4466 * engineSize) + (-5136.1274 * model_ A Class) + (-7839.7146 * model_ B Class) + (-5721.5492 * model_ C Class) + (-6210.7999 * model_ CL Class) + (-5187.9780 * model_ CLA Class) + (-3020.2951 * model_ CLC Class) + (-1567.9213 * model_ CLK) + (-6095.3489 * model_ CLS Class) + (-4180.5088 * model_ E Class) + (53873.8685 * model_ G Class) + (-4173.7563 * model_ GL Class) + (-7399.4666 * model_ GLA Class) + (747.1302 * model_ GLB Class) + (-818.2329 * model_ GLC Class) + (1565.8302 * model_ GLE Class) + (4505.9866 * model_ GLS Class) + (1148.3186 * model_ M Class) + (-1133.8473 * model_ R Class) + (6323.3326 * model_ S Class) + (-5189.1113 * model_ SL CLASS) + (-2394.5984 * model_ SLK) + (-129.5069 * model_ V Class) + (-8256.3399 * model_ X-CLASS) + (-1209.6356 * model_180) + (-8928.2316 * model_200) + (-10010.5658 * model_220) + (26439.0693 * model_230) + (2124.1269 * transmission_Automatic) + (-40.9900 * transmission_Manual) + (-4196.2965 * transmission_Other) + (2113.1596 * transmission_Semi-Auto) + (-9635.6153 * fuelType_Diesel) + (2139.8923 * fuelType_Hybrid) + (15559.7937 * fuelType_Other) + (-8064.0708 * fuelType_Petrol)\n",
    "\n",
    "2. Because we want to be able to compare features across the dataset. By standardizing each feature across samples, the model can obtain global information about what is “high” or “low” for each feature. Standardizing per sample would not help us find the patterns we want the model to learn.\n",
    "\n",
    "3. Since our categories don't have any order, we use one-hot encoding so the model doesn’t mistakenly treat categories as bigger or smaller. It keeps them separate and equal. This is safer because regression will treat the values as if the categories are numeric and ordered in some way if we map each categorical value to an integer. This way, the coefficient on each one-hot variable directly tell us the contribution of that category relative to the baseline (treat them as individiual options), not based on numeric order\n",
    "\n",
    "4. We should generate the polynomial features first, then standardize them. This is because polynomial features can be much larger or smaller than the original feature. If we only standardize the original features first, the new polynomial ones will result in very different ranges. By standardizing after expansion, the original and polynomial feature are on the same scale so the model avoids being biased to large-valued polynomial features and treats all features fairly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVz38ASe-gGV"
   },
   "source": [
    "# Save the Code File\n",
    "Please save your code as a Jupyter Notebook file (Lab1.ipynb) and submit it to eeclass along with your prediction files (Lab1_basic.csv and Lab1_advanced.csv)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ML (lab3)",
   "language": "python",
   "name": "lab3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
